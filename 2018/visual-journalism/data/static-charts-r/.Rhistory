overall_status <- tmp[6] %>%
html_text() %>%
trimws()
recruit_status <- tmp[7] %>%
html_text() %>%
trimws()
recruit_start <- tml[34] %>%
html_text() %>%
trimws()
recruit_end <- tml[35] %>%
html_text() %>%
trimws()
tmp2 <- data.frame(id,overall_status,recruit_status,recruit_start,recruit_end)
trial_data <- bind_rows(trial_data,tmp2)
}
for (id in titles$id) {
url <- paste0(base_url,id)
print(url)
tmp <- read_html(url) %>%
html_nodes("dd,p")
overall_status <- tmp[6] %>%
html_text() %>%
trimws()
recruit_status <- tmp[7] %>%
html_text() %>%
trimws()
recruit_start <- tmp[34] %>%
html_text() %>%
trimws()
recruit_end <- tmp[35] %>%
html_text() %>%
trimws()
tmp2 <- data.frame(id,overall_status,recruit_status,recruit_start,recruit_end)
trial_data <- bind_rows(trial_data,tmp2)
}
View(trial_data)
trial_data <- data.frame()
for (id in titles$id) {
url <- paste0(base_url,id)
print(url)
tmp <- read_html(url) %>%
html_nodes("dd")
overall_status <- tmp[6] %>%
html_text() %>%
trimws()
recruit_status <- tmp[7] %>%
html_text() %>%
trimws()
tmp2 <- data.frame(id,overall_status,recruit_status,recruit_start,recruit_end)
trial_data <- bind_rows(trial_data,tmp2)
}
View(trial_data)
trial_data <- data.frame()
for (id in titles$id) {
url <- paste0(base_url,id)
print(url)
tmp <- read_html(url) %>%
html_nodes("dd")
overall_status <- tmp[6] %>%
html_text() %>%
trimws()
recruit_status <- tmp[7] %>%
html_text() %>%
trimws()
tmp2 <- data.frame(id,overall_status,recruit_status)
trial_data <- bind_rows(trial_data,tmp2)
}
View(trial_data)
# load the Lahman package
library(Lahman)
Salaries <- filter(2016)
library(dplyr)
library(readr)
# convert Lahman tables to local data frames, with data for 2015 only for Teams and Salaries
Teams <- filter(Teams, yearID == 2016)
View(Teams)
Salaries <- filter(Salaries, yearID == 2016)
View(Salaries)
View(Teams)
mlb_salaries_2016 <- Salaries %>%
left_join(Master, by="playerID") %>%
left_join(Teams, by="teamID") %>%
mutate(salary_mil=salary/1000000, nameFull=paste(nameFirst, nameLast, sep=" ")) %>%
rename(teamName=name) %>%
select(playerID, nameFirst, nameLast, nameFull, teamID, teamName, salary, salary_mil)
View(mlb_salaries_2016)
# convert Lahman tables to local data frames, with data for 2015 only for Teams and Salaries
Teams <- filter(Teams, yearID == 2017)
install.packages("quantmod")
install.packages(c("backports", "broom", "curl", "devtools", "digest", "foreach", "ggiraph", "git2r", "glue", "hms", "iterators", "lazyeval", "lubridate", "Matrix", "mgcv", "officer", "openssl", "purrr", "quantmod", "raster", "Rcpp", "reshape2", "rgdal", "rgeos", "rlang", "rmarkdown", "rprojroot", "Rttf2pt1", "rvg", "stringi", "tidycensus", "tidyr", "tidyselect", "tidyverse", "webshot", "withr", "xts", "yaml"), lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# convert Lahman tables to local data frames, with data for 2015 only for Teams and Salaries
Teams <- filter(Teams, yearID == 2017)
# convert Lahman tables to local data frames, with data for 2015 only for Teams and Salaries
Teams <- filter(Teams, yearID == 2016)
load("~/SpiderOak Hive/twitter_congress/analysis.RData")
### note, when combine the CSVs later, need to send screennames to lower case!!!
# load required packages
library(readr)
library(dplyr)
library(twitteR)
library(stringr)
library(lubridate)
# set working directory
# setwd("~/twitter_congress")
#################################################
# get data on members of congress, including twitter accounts, from https://github.com/unitedstates/
curr_members <- read_csv("http://theunitedstates.io/congress-legislators/legislators-current.csv")
# filter out members with no qualifying twitter account
curr_members <- curr_members %>%
filter(!is.na(twitter))
#################################################
# retrieve current members' tweets
# twitter authorization
consumer_key <- "gUdYqHriyJn8ejsBuAfmeBtFE"
consumer_secret <- "G5qSxF87kHafPuP1mzlwabVKGj14pSBvwdIEuQ9DkXGMy8GhtV"
access_token <- "589535421-vwvWXqgjGjQNnenMSDOnUPszphiMdBJm6iFsG92G"
access_secret <- "aHq7dQnZVXKsVvYXajtRlwNWDW8sUkydCGhacU6pjtUi9"
options(httr_oauth_cache=T) # this will enable the use of a local file to cache OAuth access credentials between R sessions.
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
# get members' twitter timelines
members_tweets <- data_frame()
x <- 1
for (n in curr_members$twitter) {
print(paste0(n," ",x," of ",length(curr_members$twitter)))
try(tmp_list <- userTimeline(n,includeRts=T,n=500))
try(tmp <- twListToDF(tmp_list))
try(members_tweets <- bind_rows(members_tweets,tmp))
rm(tmp_list,tmp)
Sys.sleep(60)
x <- x+1
# save data every 20 members, in case of crashes
if (x%%20==0) save.image("twitter_congress_update.RData")
}
# who/what have we got?
members_tweets_summary <- members_tweets %>%
mutate(screenName = tolower(screenName)) %>%
group_by(screenName) %>%
summarise(tweets=n(),
earliest=min(created))
# anyone missing?
members_screenNames <- curr_members %>%
select(twitter) %>%
rename(screenName = twitter) %>%
mutate(screenName = tolower(screenName))
missing <- anti_join(members_screenNames,members_tweets_summary)
# processing failed accounts
members_tweets_missing <- data_frame()
x <- 1
for (n in missing$screenName) {
print(paste0(n," ",x," of ",length(missing$screenName)))
try(tmp_list <- userTimeline(n,includeRts=T,500))
try(tmp <- twListToDF(tmp_list))
try(members_tweets_missing <- bind_rows(members_tweets_missing,tmp))
rm(tmp_list,tmp)
Sys.sleep(60)
x <- x+1
}
members_tweets <- bind_rows(members_tweets,members_tweets_missing)
# save as CSV with date stamp
write.csv(members_tweets, paste0("downloads/members_tweets_",Sys.Date(),".csv"), row.names=FALSE, na="")
# who/what have we got?
members_tweets_summary <- members_tweets %>%
mutate(screenName = tolower(screenName)) %>%
group_by(screenName) %>%
summarise(tweets=n(),
earliest=min(created))
#############################################################################
# get tweets for Trump, Pence, Ryan, Pelosi, McConnell, Schumer, Sanders
# leaders <- c("realDonaldTrump","VP","SpeakerRyan","NancyPelosi","SenateMajLdr","SenSchumer","SenSanders")
leaders <- c("realDonaldTrump")
# get leaders' twitter timelines
leaders_tweets <- data_frame()
for (l in leaders) {
print(l)
try(tmp_list <- userTimeline(l,includeRts=T,n=500))
try(tmp <- twListToDF(tmp_list))
try(leaders_tweets <- bind_rows(leaders_tweets,tmp))
rm(tmp_list,tmp)
Sys.sleep(60)
}
# who/what have we got?
leaders_tweets_summary <- leaders_tweets %>%
mutate(screenName = tolower(screenName)) %>%
group_by(screenName) %>%
summarise(tweets=n(),
earliest=min(created))
leaders_screenNames <- data_frame(leaders) %>%
rename(screenName = leaders) %>%
mutate(screenName = tolower(screenName))
missing <- anti_join(leaders_screenNames,leaders_tweets_summary)
# processing failed accounts
leaders_tweets_missing <- data_frame()
x <- 1
for (n in missing$screenName) {
print(paste0(n," ",x," of ",length(missing$screenName)))
try(tmp_list <- userTimeline(n,includeRts=T,n=500))
try(tmp <- twListToDF(tmp_list))
try(leaders_tweets_missing <- bind_rows(leaders_tweets_missing,tmp))
rm(tmp_list,tmp)
Sys.sleep(60)
x <- x+1
}
leaders_tweets <- bind_rows(leaders_tweets,leaders_tweets_missing)
# bind together
tweets <- bind_rows(leaders_tweets,members_tweets) %>%
mutate(text = str_replace_all(text, "[\r\n]" , ""))
# save as CSV with timestamp
write.csv(tweets, paste0("tweets_",Sys.Date(),".csv"), na="")
install.packages("viridis")
install.packages(c("dbplyr", "digest", "DT", "ellipse", "git2r", "haven", "hexbin", "hms", "htmlTable", "htmlwidgets", "irlba", "knitr", "MASS", "mgcv", "officer", "Rcpp", "RCurl", "reprex", "rlang", "rpart", "rprojroot", "sf", "sp", "tibble", "tidycensus", "tigris", "TTR", "units", "xml2", "zoo"), lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
setwd("~/Desktop/data-processing-r")
save.image("~/Desktop/data-processing-r/data-processing.RData")
install.packages("tidyverse", lib="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
# load packages to read, write and process data
library(readr)
library(dplyr)
nations1 <- read_csv("nations1.csv")
nations2 <- read_csv("nations2.csv")
View(nations1)
str(nations1)
nations1$population
nations1$population <- as.integer(nations1$population)
str(nations1)
summary(nations1)
longevity <- nations1 %>%
filter(year == 2015 & !is.na(life_expect)) %>%
select(country, life_expect, income, region)
View(longevity)
high_income_short_life <- longevity %>%
filter(income == "High income") %>%
arrange(life_expect) %>%
head(10)
View(high_income_short_life)
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = c(1:195)) %>%
filter(rank <= 20 | country == "United States")
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = c(1:length(longevity))) %>%
filter(rank <= 20 | country == "United States")
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = c(1:length(longevity$isoc3))) %>%
filter(rank <= 20 | country == "United States")
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = c(1:length(longevity$iso3c))) %>%
filter(rank <= 20 | country == "United States")
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = c(1:length(longevity$country))) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
arrange(desc(life_expect)) %>%
mutate(rank = rank(life_expect)) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(life_expect)) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(desc(life_expect))) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(desc(life_expect))) %>%
arrange(desc(rank)) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(desc(life_expect))) %>%
arrange(rank) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(life_expect)) %>%
arrange(rank) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank = rank(desc(life_expect))) %>%
arrange(rank) %>%
filter(rank <= 20 | country == "United States")
# plus the United States with its rank, if it lies outside the top 20
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le) %>%
filter(rank <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le) %>%
filter(rank <= 20 | country == "United States")
str(long_life)
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le)
View(long_life)
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le) %>%
filter(rank <= 20 | country == "United States")
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le) %>%
filter(rank_le <= 20 | country == "United States")
View(long_life)
long_life <- longevity %>%
mutate(rank_le = rank(desc(life_expect))) %>%
arrange(rank_le) %>%
filter(rank_le <= 20 | grepl("United States|Russia", country)
)
View(long_life)
longevity_summary <- nations1 %>%
filter(!is.na(life_expect)) %>%
group_by(year) %>%
summarize(countries = n(),
max_life_expect = max(life_expect),
min_life_expect = min(life_expect)) %>%
mutate(range_life_expect = max_life_expect - min_life_expect) %>%
arrange(desc(year))
View(longevity_summary)
longevity_summary <- nations1 %>%
filter(!is.na(life_expect)) %>%
group_by(year) %>%
summarize(countries = n(),
max_life_expect = max(life_expect),
min_life_expect = min(life_expect),
range_life_expect = range(life_expect)) %>%
mutate(range_life_expect = max_life_expect - min_life_expect) %>%
arrange(desc(year))
View(longevity_summary)
longevity_summary <- nations1 %>%
filter(!is.na(life_expect)) %>%
group_by(year) %>%
summarize(countries = n(),
max_life_expect = max(life_expect),
min_life_expect = min(life_expect),
range_life_expect = range(life_expect)) %>%
arrange(desc(year))
# total GDP, in trillions of dollars, by region, over time
gdp_regions <- nations1 %>%
mutate(gdp = gdp_percap * population,
gdp_tn = gdp/1000000000000) %>%
group_by(region, year) %>%
summarize(total_gdp_tn = sum(gdp_tn, na.rm = TRUE))
View(gdp_regions)
gdp_regions <- nations1 %>%
mutate(gdp = gdp_percap * population,
gdp_tn = gdp/10^12) %>%
group_by(region, year) %>%
summarize(total_gdp_tn = sum(gdp_tn, na.rm = TRUE))
View(gdp_regions)
# join nations1 to nations2
nations <- inner_join(nations1, nations2)
# join nations1 to nations2
nations <- left_join(nations1, nations2)
co2_regions <- nations %>%
mutate(co2 = co2_percap * population / 10^9) %>%
group_by(region, year) %>%
summarize(total_co2 = sum(co2, na.rm = TRUE))
View(co2_regions)
co2_regions <- nations %>%
filter(year != 2015) %>%
mutate(co2 = co2_percap * population / 10^9) %>%
group_by(region, year) %>%
summarize(total_co2 = sum(co2, na.rm = TRUE))
View(co2_regions)
immun <- read_csv("kindergarten.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
immun_2015 <- read_csv("kindergarten_2015.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
View(immun)
View(immun_2015)
immun_2015 <- read_csv("kindergarten_2015.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_number()))
View(immun_2015)
write.csv(immun_2015, "kindergarten_2015.csv", row.names=F, na="")
View(immun)
write.csv(immun, "kindergarten.csv", row.names=F, na="")
immun <- read_csv("kindergarten.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
immun_2015 <- read_csv("kindergarten_2015.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
# append the 2015 data to the older data
immun <- bind_rows(immun, immun_2015)
View(immun)
immun_2015 <- read_csv("kindergarten2015.csv")
immun_2015 <- read.csv("kindergarten2015.csv") %>%
# append the 2015 data to the older data
immun <- bind_rows(immun, immun_2015)
View(immun_2015)
immun_2015 <- read.csv("kindergarten2015.csv") %>%
select(1:4,6:8)
View(immun_2015)
immun_2015 <- read.csv("kindergarten2015.csv") %>%
select(1:4,6:8) %>%
mutate(start_year = 2015)
View(immun_2015)
write.csv(immun_2015, "kindergarten_2015.csv", row.names = F, na="")
immun <- read_csv("kindergarten.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
immun_2015 <- read_csv("kindergarten_2015.csv",  col_types = list(
county = col_character(),
district = col_character(),
sch_code = col_character(),
pub_priv = col_character(),
school = col_character(),
enrollment = col_integer(),
complete  = col_integer(),
start_year = col_integer()))
# append the 2015 data to the older data
immun <- bind_rows(immun, immun_2015)
# save session data
save.image("~/Desktop/data-processing-r/data-processing.RData")
View(immun)
immun_year <- immun %>%
group_by(start_year) %>%
summarize(enrolled = sum(enrollment, na.rm=TRUE),
completed = sum(complete, na.rm=TRUE)) %>%
mutate(pc_incomplete = round(((enrolled-completed)/enrolled*100),2))
View(immun_year)
immun_counties_year <- immun %>%
group_by(county,start_year) %>%
summarize(enrolled = sum(enrollment, na.rm = TRUE),
completed = sum(complete, na.rm = TRUE)) %>%
mutate(pc_incomplete = round(((enrolled-completed)/enrolled*100),2))
View(immun_counties_year)
top5 <- immun %>%
group_by(county) %>%
summarize(enrolled = sum(enrollment, na.rm = TRUE)) %>%
arrange(desc(enrolled)) %>%
head(5) %>%
select(county)
View(top5)
# proportion incomplete, top 5 counties by enrollment, by year
immun_top5_year <- semi_join(immun_counties_year, top5)
View(immun_year)
View(immun_counties_year)
View(immun)
setwd("~/Desktop/data-processing-r")
setwd("~/Dropbox/ucsc/2018/visual-journalism/data/static-charts-r")
write.csv(immun,"kindergarten.csv",row.names = F, na="")
# create list of indicators to be imported
indic_list <- c("NY.GDP.PCAP.PP.CD", "SP.DYN.LE00.IN", "SP.POP.TOTL", "EN.ATM.CO2E.PC")
indicators <- WDI(indicator=indic_list, country="all", start=1990, end=2015, extra=T, cache=NULL) %>%
rename(gdp_percap=NY.GDP.PCAP.PP.CD, life_expect=SP.DYN.LE00.IN, population=SP.POP.TOTL, co2_percap=EN.ATM.CO2E.PC) %>%
filter(income != "Aggregates") %>%
select(1,8,2:7,9,13)
library(WDI)
library(dplyr)
library(readr)
library(stringr)
indicators <- WDI(indicator=indic_list, country="all", start=1990, end=2015, extra=T, cache=NULL) %>%
rename(gdp_percap=NY.GDP.PCAP.PP.CD, life_expect=SP.DYN.LE00.IN, population=SP.POP.TOTL, co2_percap=EN.ATM.CO2E.PC) %>%
filter(income != "Aggregates") %>%
select(1,8,2:7,9,13)
indicators$region <- gsub("all income levels","", indicators$region)
indicators$region <- gsub("\\(|\\)","", indicators$region)
indicators$region <- str_trim(indicators$region)
indicators$income <- gsub(": nonOECD","", indicators$income)
indicators$income <- gsub(": OECD","", indicators$income)
# write to csv
write.csv(indicators, "nations.csv", na="", row.names = F)
